{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#from dotenv import load_dotenv\n",
    "from intake import open_catalog\n",
    "import intake\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "import datetime\n",
    "from pystac_client import Client as psc\n",
    "import stackstac\n",
    "import numpy\n",
    "\n",
    "#import dask.distributed\n",
    "\n",
    "\n",
    "from pyproj import CRS\n",
    "from pyproj import Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio.features\n",
    "import xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables à changer pour récupérer les données sources de la chaîne des feux dans le système de l'oeil\n",
    "# Utiliser intake et dotenv \n",
    "# Intake pour ouvrir le catalogue à partir de la db postgres de l'OEIL\n",
    "# dotenv pour gérer les credentials et les chemins d'accès\n",
    "\n",
    "PATH_GEOM = r\"E:\\FILES\\OEIL\\datas\\sentinel_surfaces_detectees_sept_oct_2023.gpkg\"\n",
    "\n",
    "URL = \"https://earth-search.aws.element84.com/v1\"\n",
    "URL_2 = \"https://catalogue.dataspace.copernicus.eu/stac\"\n",
    "URL_3 = \"https://services.sentinel-hub.com/api/v1/catalog/1.0.0/\"\n",
    "URL_4 = \"https://earthengine.openeo.org/v1.0/\"\n",
    "\n",
    "collection = \"SENTINEL-2\"\n",
    "collect_amazon ='sentinel-2-l2a'\n",
    "collect_EE = 'COPERNICUS/S2_SR_HARMONIZED'\n",
    "\n",
    "crs_rgnc = CRS.from_epsg(3163)\n",
    "crs_4326 = CRS.from_epsg(4326)\n",
    "transformer = Transformer.from_crs(crs_rgnc, crs_4326)\n",
    "\n",
    "# On lit le fichier des surfaces brûlées dans un geodataframe\n",
    "ba_test = gpd.read_file(PATH_GEOM)\n",
    "\n",
    "# On créer une nouvelle colonne pour avoir un datetime de la date\n",
    "ba_test['date_']= pd.to_datetime(ba_test['date'], format='%Y-%m-%d').dt.date\n",
    "\n",
    "# On passe de multipolygon à polygon.\n",
    "ba_test = ba_test.explode()\n",
    "ba_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_test[ba_test['surface_id']==359919]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On établit la liste des communes de notre geodataframe\n",
    "liste_commune = list(set(ba_test[\"commune\"]))\n",
    "\n",
    "# On récupère les surfaces_id qui ont été photo interprétés, fournis par Oriane\n",
    "surfaces_id = {\n",
    "    \"burned\" : [358032, 358018, 358010, 359919, 359594, 359614, 358008, 359524, 359592, 359944],\n",
    "    \"unburned\"  : [357997, 358001, 358002, 358017, 358012, 359543, 359788, 359498, 359545, 360203],\n",
    "    \"doubt\": [358026, 358033,359595, 359964, 362134, 362171, 362192, 362851, 360718, 359666]\n",
    "}\n",
    "\n",
    "# On prend un intervalle de temps avec 120 jours avant la première date de détection de surface brûlée du geopackage des surfaces brûlées\n",
    "datemin = (min(ba_test['date_']) - datetime.timedelta(days=120)).strftime('%Y-%m-%d') \n",
    "datemax = max(ba_test['date_']).strftime('%Y-%m-%d')\n",
    "\n",
    "# On fait un test sur la surface brulée 358032\n",
    "ba_test_filter = ba_test[ba_test[\"surface_id\"]==358032]\n",
    "# On créer une séries des dates de détection des surfaces brûlées pour filtrer les images sentinel2\n",
    "dates_burnedarea = ba_test_filter['date_'].values\n",
    "bbox = ba_test_filter[\"geometry\"].to_crs(4326).total_bounds\n",
    "\n",
    "# On prend un intervalle de temps avec 120 jours avant la première date de détection de surface brûlée du geopackage des surfaces brûlées\n",
    "datemin = (min(ba_test_filter['date_']) - datetime.timedelta(days=120)).strftime('%Y-%m-%d') \n",
    "datemax = (max(ba_test_filter['date_'])+ datetime.timedelta(days=40)).strftime('%Y-%m-%d')\n",
    "\n",
    "dates = f'{datemin}/{datemax}'\n",
    "print(f'Emprise spatiale globale des formes identifiées {bbox}')\n",
    "\n",
    "print(f'Interval temporel {dates}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = psc.open(URL)\n",
    "cc=40\n",
    "search = client.search(\n",
    "    collections=[collect_amazon],\n",
    "    bbox=bbox,\n",
    "    datetime=dates\n",
    "    )\n",
    "\n",
    "print(f\"{search.matched()} scenes Sentinel-2 L2A trouvées dans l'intervalle temporel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = search.item_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_test_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinel_stack = stackstac.stack(\n",
    "                          items,\n",
    "                          bounds_latlon=[bbox[0], bbox[1],  bbox[2],  bbox[3]],\n",
    "\n",
    "                          gdal_env=stackstac.DEFAULT_GDAL_ENV.updated(\n",
    "                               {'GDAL_HTTP_MAX_RETRY': 3,\n",
    "                                'GDAL_HTTP_RETRY_DELAY': 5,\n",
    "                               }),\n",
    "                          epsg=4326\n",
    "                          ).rename({'x': 'lon', 'y': 'lat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indices = sentinel_stack.sel(band=[\"blue\",\"rededge2\", \"rededge3\", \"green\",\"red\", \"nir\",\"nir08\",\"swir22\", \"scl\"]).to_dataset(dim='band')\n",
    "#rgb = sentinel_stack.sel(band=[\"red\", \"green\", \"blue\"]).compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in data_indices.data_vars :\n",
    "    print(type(elt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_times = pd.to_datetime(sentinel_stack['time']).date\n",
    "images_to_keep = []\n",
    "\n",
    "for i, time in enumerate(data_times):\n",
    "  if time in dates_burnedarea:\n",
    "    images_to_keep.append(i)\n",
    "    print(f\"on conserve automatiquement l'image {i}\")\n",
    "    continue\n",
    "  \n",
    "  scl_data = sentinel_stack.isel(time = i).sel(band = \"scl\") \n",
    "  mask = (scl_data>=4) & (scl_data<=7)\n",
    "  filtered_data = scl_data.where(mask)\n",
    "  percentage = (filtered_data.count() / scl_data.count()) *100\n",
    "  \n",
    "  if percentage > 90:\n",
    "    print(f\"on prend l'image sufisamment peu couverte {i}\")\n",
    "    images_to_keep.append(i)\n",
    "\n",
    "data_to_keep = sentinel_stack.isel(time=images_to_keep)\n",
    "\n",
    "print(f\"Nombre d'images après filtrage :{len(images_to_keep)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indices = data_to_keep.sel(band=[\"blue\",\"rededge2\", \"rededge3\", \"green\",\"red\", \"nir\",\"nir08\",\"swir22\", \"scl\"]).to_dataset(dim='band')\n",
    "data_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indices = data_to_keep.sel(band=[\"blue\",\"rededge2\", \"rededge3\", \"green\",\"red\", \"nir\",\"nir08\",\"swir22\", \"scl\"]).to_dataset(dim='band')\n",
    "\n",
    "\"\"\"\n",
    "Correction des valeurs de bandes, on avait des valeurs négatives de reflectance par endroit\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "data_indices[\"red+\"]=data_indices[\"red\"].where(lambda x : x>0, lambda x : -x)\n",
    "data_indices[\"nir+\"]=data_indices[\"nir\"].where(lambda x : x>0, lambda x : -x)\n",
    "data_indices[\"swir22+\"]=data_indices[\"swir22\"].where(lambda x : x>0, lambda x : -x)\n",
    "data_indices[\"green+\"]=data_indices[\"green\"].where(lambda x : x>0, lambda x : -x)\n",
    "data_indices[\"blue+\"]=data_indices[\"blue\"].where(lambda x : x>0, lambda x : -x)\n",
    "data_indices[\"nir08+\"]=data_indices[\"nir08\"].where(lambda x : x>0, lambda x : -x)\n",
    "data_indices[\"rededge2+\"]=data_indices[\"rededge2\"].where(lambda x : x>0, lambda x : -x)\n",
    "data_indices[\"rededge3+\"]=data_indices[\"rededge3\"].where(lambda x : x>0, lambda x : -x)\n",
    "\"\"\"\n",
    "data_indices[\"red\"] = data_indices[\"red\"]+0.1\n",
    "data_indices[\"nir\"] = data_indices[\"nir\"]+0.1\n",
    "data_indices[\"swir22\"] = data_indices[\"swir22\"]+0.1\n",
    "data_indices[\"green\"] = data_indices[\"green\"]+0.1\n",
    "data_indices[\"blue\"] = data_indices[\"blue\"]+0.1\n",
    "data_indices[\"nir08\"] = data_indices[\"nir08\"]+0.1\n",
    "data_indices[\"rededge2\"] = data_indices[\"rededge2\"]+0.1\n",
    "data_indices[\"rededge3\"] = data_indices[\"rededge3\"]+0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indices['ndvi'] = ((data_indices['nir'].astype(float) - data_indices['red'].astype(float))/(data_indices['nir'].astype(float)+ data_indices['red'].astype(float)))\n",
    "\n",
    "data_indices['nbr'] = ((data_indices['nir'] - data_indices['swir22'])/(data_indices['nir'] + data_indices['swir22']))\n",
    "\n",
    "data_indices['nbr+'] = ((data_indices['swir22'] - data_indices['nir08'] - data_indices['green'] - data_indices['blue'])/(data_indices['swir22'] + data_indices['nir08'] + data_indices['green'] + data_indices['blue']))\n",
    "\n",
    "data_indices['bais2'] = (1-(numpy.sqrt((data_indices['rededge2'] * data_indices['rededge3'] * data_indices['nir08'])/data_indices['red']))*((data_indices['swir22'] - data_indices['nir08'] )/ numpy.sqrt((data_indices['swir22'] + data_indices['nir08'] ))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShapeMask = rasterio.features.geometry_mask(ba_test_filter['geometry'].to_crs(4326).apply(mapping),\n",
    "                                            out_shape =(len(data_indices.lat), len(data_indices.lon)),\n",
    "                                            transform = data_indices.transform,\n",
    "                                            invert = True)\n",
    "ShapeMask = xarray.DataArray(ShapeMask, dims = (\"lat\",\"lon\"))\n",
    "data_indices['mask'] = ShapeMask\n",
    "data_indices['mask'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1D = data_indices.where(data_indices['mask']).data_vars['ndvi'].median(dim = [\"lat\", \"lon\"])\n",
    "print(ba_test_filter[\"date_\"].iloc[0])\n",
    "data_1D.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indices[\"nbr+\"].where(data_indices[\"mask\"]).mean(dim=[\"lat\", \"lon\"]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indices[\"bais2\"].where(data_indices[\"mask\"]).mean(dim=[\"lat\", \"lon\"]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indices.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_indices['nbr'].isel(time=0)-data_indices['nbr'].isel(time=11)).plot(cmap = 'Reds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indices[\"nbr\"].where(data_indices[\"mask\"]).mean(dim=[\"lat\", \"lon\"]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indices[\"ndvi\"].isel(time=12).plot.pcolormesh(cmap=\"YlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1D = data_indices.where(data_indices['mask']).data_vars['ndvi'].mean(dim = [\"lat\", \"lon\"])\n",
    "print(ba_test_filter[\"date_\"].iloc[0])\n",
    "data_1D.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_indices.to_dataarray(dim=\"bands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rgb = dataset.sel(bands=[\"red\", \"green\", \"blue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_test_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_save = data_indices.drop([c for c in data_indices.coords if not (c in ['time', 'lat', 'lon'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_save = dataset_save.drop_vars([v for v in dataset_save.data_vars if not (v in ['ndvi', 'nbr', 'nbr+', 'bais2', 'mask'])])\n",
    "dataset_save.attrs['spec'] = str(dataset_save.attrs['spec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_save.to_netcdf(f\"{str(ba_test_filter[\"surface_id\"].iloc[0])}_{str(ba_test_filter[\"nom\"].iloc[0])}_{str(ba_test_filter[\"date\"].iloc[0])}.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_save['ndvi'].where(dataset_save['mask']).mean(dim=[\"lat\", 'lon']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install netCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
